{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49552914",
   "metadata": {},
   "source": [
    "# Trabajo Integrador: DuckDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685d9cd1",
   "metadata": {},
   "source": [
    "## Instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install duckdb --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335237e5",
   "metadata": {},
   "source": [
    "### Creando conexión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619f2e2",
   "metadata": {},
   "source": [
    "Nos permite establecer una conexión a una base de datos, por defecto, si no especificamos su nombre, la base de datos no persistirá y operará en memoria, por lo tanto no se almacenarán las tablas creadas. Trabajaremos en memoria ya que consideramos que es el fuerte de DUCKDB y su análisis es el pertinente de este trabajo de investigación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c5e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as db\n",
    "\n",
    "database = db.connect(database=\":memory:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48b092",
   "metadata": {},
   "source": [
    "##### Prueba con el dataset. En PostgreSQL almacenaremos archivos de órdenes y sus pagos. En AWS almacenaremos los productos y su categoría. El resto de archivos será almacenado de manera local, algunos en CSV y otros en PARQUET. Esta información se encuentra representada meidante un esquema en la documentación adjunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6441cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q kagglehub        \n",
    "import kagglehub, shutil, pathlib\n",
    "\n",
    "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
    "\n",
    "local_csv_files = [\n",
    "    \"olist_customers_dataset.csv\",\n",
    "    \"olist_geolocation_dataset.csv\",\n",
    "    \"olist_order_items_dataset.csv\",\n",
    "    \"olist_order_reviews_dataset.csv\",\n",
    "    \"olist_sellers_dataset.csv\",\n",
    "    ## Estos archivos se almacenaran en PSQL \n",
    "    \"olist_orders_dataset.csv\",\n",
    "    \"olist_order_payments_dataset.csv\", \n",
    "]\n",
    "\n",
    "for file_name in local_csv_files:\n",
    "    shutil.copy(f\"{path}/{file_name}\", f\"dataset/{file_name}\")\n",
    "\n",
    "for file_name in local_csv_files:\n",
    "    table = pathlib.Path(f\"dataset/{file_name}\").stem\n",
    "    database.execute(f\"\"\"\n",
    "        CREATE OR REPLACE TABLE {table} AS\n",
    "        SELECT * FROM read_csv_auto('dataset/{file_name}');\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47020f3e",
   "metadata": {},
   "source": [
    "#### Verificación básica de la creación de las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dd699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in local_csv_files:\n",
    "    table = pathlib.Path(f\"dataset/{file_name}\").stem\n",
    "    schema = database.sql(f\"DESCRIBE {table}\")\n",
    "    print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23715818",
   "metadata": {},
   "source": [
    "#### Obteniendo los datos de forma remota - Conexión con AWS S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936ae9d",
   "metadata": {},
   "source": [
    "**NOTA:** Para utilizar AWS S3 es necesario setear las credenciales para acceder al bucket, para eso debemos crear un user en la IAM de AWS, asignarle permisos y finalmente crear las claves de acceso para este usuario. Luego, estas credenciales son obtenidas desde un .env.\n",
    "Es importante que la región del bucket y del usuario sean la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b45604",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  \n",
    "\n",
    "import os\n",
    "\n",
    "database.sql(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "database.sql(f\"\"\"\n",
    "SET s3_region='{os.getenv(\"AWS_REGION\")}';\n",
    "SET s3_access_key_id='{os.getenv(\"AWS_ACCESS_KEY_ID\")}';\n",
    "SET s3_secret_access_key='{os.getenv(\"AWS_SECRET_ACCESS_KEY\")}';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ee7dd",
   "metadata": {},
   "source": [
    "### Creando las tablas con los datos de forma remota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adde13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "database.sql(f\"\"\"\n",
    " CREATE OR REPLACE TABLE olist_products_dataset AS\n",
    "        SELECT * FROM read_csv_auto('s3://ti-quadrelli-ribarov/olist_products_dataset.csv');\n",
    "\"\"\")\n",
    "\n",
    "database.sql(f\"\"\"\n",
    " CREATE OR REPLACE TABLE product_category_name_translation AS\n",
    "        SELECT * FROM read_csv_auto('s3://ti-quadrelli-ribarov/product_category_name_translation.csv');\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b1017",
   "metadata": {},
   "source": [
    "#### Validación básica de la creación de las tablas con los datos remotos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_csv_files  = [\n",
    "    \"olist_products_dataset.csv\",\n",
    "    \"product_category_name_translation.csv\",\n",
    "]\n",
    "\n",
    "for file_name in remote_csv_files:\n",
    "    table = pathlib.Path(f\"dataset/{file_name}\").stem\n",
    "    schema = database.sql(f\"DESCRIBE {table}\")\n",
    "    print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536cfe15",
   "metadata": {},
   "source": [
    "#### Obteniendo los datos desde PostgreeSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0d62e",
   "metadata": {},
   "source": [
    "#### Nota: este paso se podría haber hecho sin DuckDB, mismo desde un manejador de base de datos como DBeaver o con la librería Pandas, sin embargo, nuevamente debido al objetivo de este proyecto, se eligió realizarlo utilizando DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5003d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Esta celda utiliza duckdb para conectarse a PostgreSQL, crea la base de datos trabajo integrador\n",
    "# en caso de que no exista \n",
    "\n",
    "database.execute(\"INSTALL postgres;\")\n",
    "database.execute(\"LOAD postgres;\")\n",
    "\n",
    "try:\n",
    "    database.execute(\"DETACH pgadmin;\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "conninfo = f\"host={os.getenv('PG_HOST')} port={os.getenv('PG_PORT')} user={os.getenv('PG_USER')} password={os.getenv('PG_PASSWORD')} dbname=postgres\"\n",
    "database.execute(f\"ATTACH '{conninfo}' AS pgadmin (TYPE postgres);\")\n",
    "\n",
    "exists = database.execute(\"\"\"\n",
    "    SELECT COUNT(*) > 0\n",
    "    FROM postgres_query(\n",
    "        'pgadmin',\n",
    "        $$SELECT 1 FROM pg_database WHERE datname = 'trabajo_integrador'$$\n",
    "    );\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "if not exists:\n",
    "    database.execute(\"\"\"\n",
    "        CALL postgres_execute(\n",
    "            'pgadmin',\n",
    "            $$CREATE DATABASE trabajo_integrador$$,\n",
    "            use_transaction => false\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "database.execute(\"DETACH pgadmin;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79839974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, os\n",
    "\n",
    "orders_csv   = pathlib.Path(\"olist_orders_dataset.csv\")\n",
    "payments_dataset = pathlib.Path(\"olist_order_payments_dataset.csv\")\n",
    "   \n",
    "\n",
    "conninfo = f\"host={os.getenv(\"PG_HOST\")} port={os.getenv(\"PG_PORT\")} user={os.getenv(\"PG_USER\")} password={os.getenv(\"PG_PASSWORD\")} dbname={os.getenv(\"PG_DB\")}\"\n",
    "database.execute(f\"ATTACH '{conninfo}' AS pgdb (TYPE postgres);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630345f",
   "metadata": {},
   "source": [
    "#### Creación de tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6acf563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "orders_csv = pathlib.Path(path) / \"olist_orders_dataset.csv\"\n",
    "payments_dataset = pathlib.Path(path) / \"olist_order_payments_dataset.csv\"\n",
    "\n",
    "database.execute(f\"\"\"\n",
    "    DROP TABLE IF EXISTS pgdb.olist_orders;\n",
    "    CREATE TABLE pgdb.olist_orders AS\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('{orders_csv.as_posix()}', HEADER=TRUE);\n",
    "\"\"\")\n",
    "\n",
    "database.execute(f\"\"\"\n",
    "    DROP TABLE IF EXISTS pgdb.olist_orders_payments;\n",
    "    CREATE TABLE pgdb.olist_orders_payments AS\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('{payments_dataset.as_posix()}', HEADER=TRUE);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgreee_csv_files  = [\n",
    "   \"olist_orders\", \n",
    "   \"olist_orders_payments\"\n",
    "]\n",
    "\n",
    "for file_name in postgreee_csv_files:\n",
    "    table = pathlib.Path(f\"dataset/{file_name}\").stem\n",
    "    schema = database.sql(f\"DESCRIBE pgdb.{table}\")\n",
    "    print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1742f",
   "metadata": {},
   "source": [
    "### Exploracion del dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
